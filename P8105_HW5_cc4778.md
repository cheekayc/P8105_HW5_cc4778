Homework 5
================
Chee Kay Cheong

# Problem 1

Create a list to read and store all the csv files located in the *Data*
folder.

``` r
# I first create a directory that contains the path to all the csv files stored in the Data folder.
Data = "C:/Users/Chu Chu/Desktop/R/Homework/HW5/Data/"

# Then I create a list that will contain all the csv file from the Data folder.
study_list = 
  Data %>% 
  # The "dir_ls" function returns filenames as a named fs_path character vector. 
  # The names are equivalent to the values, which is useful for passing onto functions like purrr::map_df().
  dir_ls() %>% 
  map(
    # Then, map a function that will read csv files.
    .f = function(path) {
      read_csv(path)
    }
  )
```

Create a single dataframe that combines all data in each csv files.

``` r
# I create a dataframe that read the list of csv files and bind all the rows into one dataframe.
long_study = 
  study_list %>% 
  # "set_names" allows R to show all the columns and values from the list of csv files.
  set_names(dir_ls(Data)) %>% 
  # Then, bind all of them together to make one tidy dataframe.
  bind_rows(.id = "file_path") %>% 
  # Create two variables "arm" & "subject_ID" for each observation.
  mutate(
    arm = str_replace(file_path, "^C:/Users/Chu Chu/Desktop/R/Homework/HW5/Data/", ""),
    arm = str_replace(arm, ".csv$", "")) %>% 
    separate(arm, c('arm', 'subject_ID')) %>% 
  select(arm, subject_ID, week_1:week_8, -file_path) %>% 
  # pivot_longer so we can do some analysis later
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observations",
    names_prefix = "week_")

long_study
```

    ## # A tibble: 160 × 4
    ##    arm   subject_ID week  observations
    ##    <chr> <chr>      <chr>        <dbl>
    ##  1 con   01         1             0.2 
    ##  2 con   01         2            -1.31
    ##  3 con   01         3             0.66
    ##  4 con   01         4             1.96
    ##  5 con   01         5             0.23
    ##  6 con   01         6             1.09
    ##  7 con   01         7             0.05
    ##  8 con   01         8             1.94
    ##  9 con   02         1             1.13
    ## 10 con   02         2            -0.88
    ## # … with 150 more rows
