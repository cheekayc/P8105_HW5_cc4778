---
title: "Homework 5"
author: "Chee Kay Cheong"
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  fig.width = 12,
  fig.height = 8,
  out.width = "90%")

library(tidyverse)
library(fs) # Load this to use "dir_ls" and map function after that.
library(purrr)
```

# Problem 1

Create a list to read and store all the csv files located in the *Data* folder.
```{r map funstion to read multiple csv files}
# I first create a directory that contains the path to all the csv files stored in the Data folder.
Data = "C:/Users/Chu Chu/Desktop/R/Homework/HW5/Problem 1 Data/"

# Then I create a list that will contain all the csv file from the Data folder.
study_list = 
  Data %>% 
  # The "dir_ls" function returns filenames as a named fs_path character vector. 
  # The names are equivalent to the values, which is useful for passing onto functions like purrr::map_df().
  dir_ls() %>% 
  map(
    # Then, map a function that will read csv files.
    .f = function(path) {
      read_csv(path)
    }
  )
```

Create a single dataframe that combines all data in each csv files.
```{r bind rows to make one tidy dataframe}
# I create a dataframe that read the list of csv files and bind all the rows into one dataframe.
long_study = 
  study_list %>% 
  # "set_names" allows R to show all the columns and values from the list of csv files.
  set_names(dir_ls(Data)) %>% 
  # Then, bind all of them together to make one tidy dataframe.
  bind_rows(.id = "file_path") %>% 
  # Create two variables "arm" & "subject_ID" for each observation.
  mutate(
    arm = str_replace(file_path, "^C:/Users/Chu Chu/Desktop/R/Homework/HW5/Problem 1 Data/", ""),
    arm = str_replace(arm, ".csv$", "")) %>% 
    separate(arm, c('arm', 'subject_ID')) %>% 
  select(arm, subject_ID, week_1:week_8, -file_path) %>% 
  # pivot_longer so we can do some analysis later
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observations",
    names_prefix = "week_")

long_study
```

```{r}
long_study %>% 
  group_by(arm, subject_ID) %>% 
  summarize(
    n_obs = n())
```


The `long_study` dataset contains 2 arms (experimental & control). Each arm contains 10 subjects, and each subject contributes 8 observations 
over the period of 8 weeks (1 observation per week for each subject).

Everything looks fine and data are cleaned, but I don't understand what the values under `observations` are representing.

```{r spaghetti plot}
Arms_name = c(
  `con` = "Control",
  `exp` = "Experimental")

long_study %>% 
  ggplot(aes(x = week, y = observations, group = subject_ID, color = subject_ID)) +
  geom_line() + 
  stat_summary(aes(group = 1), geom = "point", fun.y = mean, shape = 17, size = 3) +
  facet_grid( . ~ arm, labeller = as_labeller(Arms_name)) +
  labs(
    x = "Week",
    y = "Observations",
    title = "Observations over time graph") +
  theme_minimal() + theme(legend.position = "bottom")
```

Based on the spaghetti plot, the overall observations over 8 weeks of time are higher in the experimental group when comparing to the control group.

In the experimental group, the mean observations are increasing with time, whereas the mean observations in the control group do not have much changes with time. 


# Problem 2

##### Raw data

```{r read raw dataset}
homicide_raw = read_csv("./Data/homicide_data.csv") 
```

The raw dataset `homicide_raw` consists of `r ncol(homicide_raw)` variables (*`r names(homicide_raw)`*) and `r nrow(homicide_raw)` observations.                                                            
Missing observations in the latitude `lat` and longitude `lon` columns are identified as `NA`, while all other columns have some `Unknown` observations.                                                    
Most variables are character vectors, except for `reported_date`, `lat`, and `lon`, which are numeric vector.                                                                                                
I noticed that the dates are recorded in *yyyymmdd* format, which are not in typical date format and are not arranged in sequence. 
Besides, `victim_age` has been identified as character vector due to several `Unknown` under the column. 

Therefore, I would convert the `reported_date` to a nice date format and convert the `victim_age` variable into a numeric vector.

##### Cleaned data

```{r clean dataset}
homicides =
  homicide_raw%>% 
  janitor::clean_names() %>% 
  mutate(
    victim_age = str_replace(victim_age, "Unknown", "NA"),
    victim_age = as.numeric(victim_age),
    reported_date = as.character(reported_date),
    reported_date = as.Date(reported_date, format = "%Y%m%d"),
    state = ifelse(city == "Tulsa", "OK", state),
    state = str_replace(state, "w", "W")) %>%
  unite(col = 'city_state', c('city', 'state'), sep = ', ')
```

##### Number of homicides & number of unsolved homicides in 50 cities

The table below shows the number of homicides and the number of unsolved homicides in each city.
```{r}
homicides %>% 
  group_by(city_state) %>% 
  summarize(
    n_case = n(),
    n_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))) %>% 
  knitr::kable()
```

From the output, I noticed that there was an error in the `homicides` dataset. There is a `city_state` named *Tulsa, Alabama* 
that has only 1 case of homicide but has 0 case of unsolved homicide. I googled and checked if there is a city named *Tulsa* 
in *Alabama*. I found that there is only one place named *Tulsa* in America, and that is in *Oklahoma*. Hence, I am pretty 
sure that there is an error in the data and decided to fix that error by changing `Tulsa, AL` to `Tulsa, OK`.

I also noticed another minor issue with the dataset from the table above - `Milwaukee, wI`.
Although it probably is not a big issue, but to keep my dataset nice and tidy, I decided to make the lowercase "w" to uppercase "W".

I will make all the changes in the code chunk named `clean dataset` above, so I am not repeating the codes and starting another 
code chunk. 


##### Baltimore

```{r Baltimore}
Baltimore = 
  homicides %>% 
  filter(city_state == "Baltimore, MD") %>% 
  group_by(city_state) %>% 
  summarize(
    n_case = n(),
    n_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")))

x_balti = Baltimore %>% pull(n_unsolved)

n_balti = Baltimore %>% pull(n_case)

list_baltimore = 
  prop.test(x_balti, n_balti) %>% 
  broom::tidy()

Baltimore_stat = 
  bind_cols(Baltimore, list_baltimore)

Baltimore_stat %>% 
  select(city_state, n_case, n_unsolved, estimate, conf.low, conf.high) %>% 
  knitr::kable()
```

In Baltimore, MD, it is estimated that **64.56%** of homicides remained unsolved. We are 95% confident that the proportion of 
unsolved homicides in Baltimore, MD lies between *62.76%* and *66.32%*.


##### All cities

```{r a neat dataframe to be used}
all_cities = 
  homicides %>% 
  group_by(city_state) %>% 
  summarize(
    n_case = n(),
    n_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))) %>% 
  nest(data = n_case:n_unsolved)
```

```{r write a function}
prop_unsolved = function(df) {

  x = df %>% pull(n_unsolved)
  
  n = df %>% pull(n_case)
  
  results = 
    prop.test(x, n) %>% 
    broom::tidy()

  result_stat = 
    bind_cols(df, results)

  result_stat %>% 
    select(estimate, conf.low, conf.high)
  
}
```

```{r apply function}
all_cities_stat = 
  all_cities %>% 
  mutate(
    map_df(all_cities[["data"]], prop_unsolved)) %>% 
  unnest(data)

all_cities_stat
```

##### Create a plot

Create a plot that shows the estimated proportion of unsolved homicides and their corresponding 95% confidence intervals for each city.

```{r bar plot with error bar}
all_cities_stat %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = estimate, y = city_state, fill = city_state)) +
  geom_bar(stat="identity") +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.5) +
  labs(
    x = "Proportion of unsolved homicide",
    y = "City, State",
    title = "Proportion of unsolved homicide with 95% CI in 50 major cities in the US") +
  theme_minimal() +
  theme(legend.position = "none")
```


# Problem 3

```{r create a list of dataframes}
sample_list = vector(mode = 'list', length = 5)
  n = 5
  for (i in 1:n) {
    sample_list[[i]] = rnorm(30, 0, 5)
  }
```

```{r create a function for list}

```




